/**
 * Sigma-Weighted Complexity Evaluator
 *
 * This module provides the core complexity scoring algorithm.
 * The actual LLM call is abstracted - users provide an evaluator function.
 *
 * The sigma-weighted system allows AI to assess task complexity
 * across multiple dimensions, producing a weighted score that
 * determines optimal agent routing.
 */
import { type ComplexityTier, type ComplexityWeights, type TierThresholds } from './weights.js';
/**
 * Raw dimension scores from evaluation (0-10 each)
 */
export interface DimensionScores {
    files_changed: number;
    lines_changed: number;
    dependency_depth: number;
    test_coverage_need: number;
    cross_module_impact: number;
    semantic_complexity: number;
    context_required: number;
    risk_level: number;
    [key: string]: number;
}
/**
 * Complete complexity score result
 */
export interface ComplexityScore {
    /** Raw scores for each dimension (0-10) */
    raw: DimensionScores;
    /** Weighted composite score (0-10) */
    weighted: number;
    /** Complexity tier based on thresholds */
    tier: ComplexityTier;
    /** AI's reasoning for the scores */
    reasoning: string;
}
/**
 * Function that performs the actual LLM evaluation
 * Implement this for your LLM provider (Ollama, OpenAI, etc.)
 */
export type LLMEvaluator = (prompt: string) => Promise<string>;
/**
 * Configuration for complexity evaluation
 */
export interface EvaluatorConfig {
    /** Custom weights (defaults to DEFAULT_WEIGHTS) */
    weights?: ComplexityWeights;
    /** Custom tier thresholds (defaults to DEFAULT_THRESHOLDS) */
    thresholds?: TierThresholds;
    /** Maximum context length to send to LLM */
    maxContextLength?: number;
}
/**
 * Generate the evaluation prompt for an LLM
 * This prompt is provider-agnostic - works with any LLM
 */
export declare function generateEvaluationPrompt(task: string, context: string, maxContext?: number): string;
/**
 * Parse and validate LLM response into dimension scores
 */
export declare function parseEvaluationResponse(response: string, weights?: ComplexityWeights): {
    scores: DimensionScores;
    reasoning: string;
};
/**
 * Calculate complexity score from parsed dimension scores
 */
export declare function calculateComplexity(scores: DimensionScores, config?: EvaluatorConfig): Omit<ComplexityScore, 'reasoning'>;
/**
 * Full evaluation using an LLM
 *
 * @example
 * ```typescript
 * // With Ollama
 * const evaluate = async (prompt: string) => {
 *   const res = await fetch('http://localhost:11434/api/generate', {
 *     method: 'POST',
 *     body: JSON.stringify({ model: 'qwen2.5-coder', prompt, stream: false })
 *   });
 *   return (await res.json()).response;
 * };
 *
 * const score = await evaluateComplexity(evaluate, 'Fix the bug', codeDiff);
 * console.log(score.tier); // 'simple'
 * console.log(score.weighted); // 3.5
 * ```
 */
export declare function evaluateComplexity(llm: LLMEvaluator, task: string, context: string, config?: EvaluatorConfig): Promise<ComplexityScore>;
/**
 * Quick complexity estimation without AI (heuristic-based)
 * Useful when LLM is unavailable or for fast pre-filtering
 */
export declare function estimateComplexityHeuristic(options: {
    filesChanged?: number;
    linesChanged?: number;
    hasTests?: boolean;
    isRefactor?: boolean;
    hasDependencyChanges?: boolean;
    isCriticalPath?: boolean;
}, config?: EvaluatorConfig): ComplexityScore;
//# sourceMappingURL=evaluator.d.ts.map